{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN6dK6W3GRxHzhHEumSam4M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sz_v652afgwX","executionInfo":{"status":"ok","timestamp":1743228192490,"user_tz":-330,"elapsed":13024,"user":{"displayName":"THIPIRISHETTY DHAN RAJ IIIT Dharwad","userId":"02884281782825347291"}},"outputId":"6bb493b5-3be4-4900-a957-d456592330a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.8.0 (from gradio)\n","  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"]}],"source":["pip install gradio\n"]},{"cell_type":"code","source":["!pip install faiss-cpu\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0wPaH9-gpp0","executionInfo":{"status":"ok","timestamp":1743228482045,"user_tz":-330,"elapsed":7905,"user":{"displayName":"THIPIRISHETTY DHAN RAJ IIIT Dharwad","userId":"02884281782825347291"}},"outputId":"0065e9e6-5669-45a2-e5b1-40d628315d47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.10.0\n"]}]},{"cell_type":"code","source":["import os\n","import faiss\n","import numpy as np\n","import pandas as pd\n","import torch\n","import gradio as gr\n","from sentence_transformers import SentenceTransformer\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","\n","# Set Hugging Face Token\n","HF_TOKEN = \"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\" # Replace with your actual token.  Never commit your real token!\n","os.environ[\"HF_TOKEN\"] = HF_TOKEN\n","\n","# Load FAISS index\n","try:\n","    faiss_index = faiss.read_index(\"medical_faiss.index\")\n","except Exception as e:\n","    print(f\"Error loading FAISS index: {e}\")\n","    faiss_index = None # or handle the error as appropriate (e.g., create a dummy index)\n","\n","# Load answers dataset\n","try:\n","    answers_df = pd.read_csv(\"medical_answers.csv\")\n","except FileNotFoundError:\n","    print(\"Error: medical_answers.csv not found.\")\n","    answers_df = None # Handle appropriately: exit, create an empty dataframe, etc.\n","except Exception as e:\n","    print(f\"Error reading medical_answers.csv: {e}\")\n","    answers_df = None # Handle appropriately.\n","\n","# Load model for query encoding\n","try:\n","    encoder_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n","except Exception as e:\n","    print(f\"Error loading sentence transformer model: {e}\")\n","    encoder_model = None # Handle the error: exit, use a different model, etc.\n","\n","\n","# Load TinyLLaMA for out-of-dataset queries\n","tiny_model_name = \"TinyLLaMA/TinyLLaMA-1.1B-Chat\"\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","try:\n","    tiny_model = AutoModelForCausalLM.from_pretrained(\n","        tiny_model_name, token=HF_TOKEN\n","    ).to(device)\n","    tiny_tokenizer = AutoTokenizer.from_pretrained(\n","        tiny_model_name, token=HF_TOKEN\n","    )\n","except Exception as e:\n","    print(f\"Error loading TinyLLaMA model: {e}\")\n","    tiny_model = None\n","    tiny_tokenizer = None\n","\n","\n","# Function to retrieve answer\n","def retrieve_answer(query):\n","    if encoder_model is None or faiss_index is None or answers_df is None:\n","        raise ValueError(\"Required models/dataframes not loaded.\")\n","\n","    query_embedding = encoder_model.encode([query], convert_to_numpy=True)\n","    D, I = faiss_index.search(query_embedding, 1)  # D is distances, I is indices\n","\n","    if len(I) == 0 or len(I[0]) == 0 or I[0][0] < 0 or I[0][0] >= len(answers_df):\n","      raise ValueError(\"No suitable answer found in FAISS index.\")\n","\n","\n","    retrieved_answer = answers_df.iloc[I[0][0]][\"answer\"]\n","    return retrieved_answer\n","\n","# Function to generate answer if not found in FAISS\n","def generate_answer(query):\n","    if tiny_model is None or tiny_tokenizer is None:\n","        raise ValueError(\"TinyLLaMA model and tokenizer not loaded.\")\n","\n","    inputs = tiny_tokenizer(query, return_tensors=\"pt\").to(device)\n","    try:\n","        outputs = tiny_model.generate(**inputs, max_new_tokens=100)\n","        response = tiny_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response\n","    except Exception as e:\n","        print(f\"Error during TinyLLaMA generation: {e}\")\n","        return \"I encountered an error while generating an answer.\" # Provide a useful message.\n","\n","\n","# FastAPI Backend\n","app = FastAPI()\n","\n","class QueryRequest(BaseModel):\n","    query: str\n","\n","@app.post(\"/chat\")\n","async def chat(request: QueryRequest):\n","    query = request.query\n","    try:\n","        answer = retrieve_answer(query)\n","        return {\"response\": answer}\n","    except ValueError as e:\n","        print(f\"Error during retrieval: {e}\")  # Log the error\n","        generated_response = generate_answer(query)\n","        return {\"response\": generated_response}\n","    except Exception as e:\n","        print(f\"Unexpected error: {e}\") # log unexpected errors\n","        return {\"response\": \"An unexpected error occurred.\"}\n","\n","# Gradio Interface\n","def chatbot_interface(user_input):\n","    try:\n","        return retrieve_answer(user_input)\n","    except ValueError as e:\n","        print(f\"Error during retrieval in Gradio: {e}\") # log errors\n","        return generate_answer(user_input)\n","    except Exception as e:\n","        print(f\"Unexpected error in Gradio: {e}\")\n","        return \"An unexpected error occurred.\"\n","\n","iface = gr.Interface(\n","    fn=chatbot_interface,\n","    inputs=gr.Textbox(placeholder=\"Ask a medical question...\"),\n","    outputs=\"text\",\n","    title=\"Medical Chatbot\",\n","    description=\"Ask medical questions. Retrieves answers from database or generates using TinyLLaMA.\"\n",")\n","\n","# Run Gradio App\n","if __name__ == \"__main__\":\n","    iface.launch(server_name=\"0.0.0.0\", server_port=7860)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":684},"id":"EwdJyzayjJho","executionInfo":{"status":"ok","timestamp":1743230155882,"user_tz":-330,"elapsed":4311,"user":{"displayName":"THIPIRISHETTY DHAN RAJ IIIT Dharwad","userId":"02884281782825347291"}},"outputId":"141a4775-eb10-48c7-fe0f-98384afbf091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error loading TinyLLaMA model: TinyLLaMA/TinyLLaMA-1.1B-Chat is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n","If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n","Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://70ec28b852d7ed35b6.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://70ec28b852d7ed35b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]}]}